{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gft(fname, dtype=float, comments='#', delimiter=None,\n",
    "               skip_header=0, skip_footer=0, converters=None,\n",
    "               missing_values=None, filling_values=None, usecols=None,\n",
    "               names=None, excludelist=None, deletechars=None,\n",
    "               replace_space='_', autostrip=False, case_sensitive=True,\n",
    "               defaultfmt=\"f%i\", unpack=None, ndmin=0, usemask=False, loose=True,\n",
    "               invalid_raise=True, max_rows=None):\n",
    "    \"\"\"\n",
    "    Load data from a text file, with missing values handled as specified.\n",
    "\n",
    "    Each line past the first `skip_header` lines is split at the `delimiter`\n",
    "    character, and characters following the `comments` character are discarded.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : file, str, pathlib.Path, list of str, generator\n",
    "        File, filename, list, or generator to read.  If the filename\n",
    "        extension is `.gz` or `.bz2`, the file is first decompressed. Note\n",
    "        that generators must return byte strings in Python 3k.  The strings\n",
    "        in a list or produced by a generator are treated as lines.\n",
    "    dtype : dtype, optional\n",
    "        Data type of the resulting array.\n",
    "        If None, the dtypes will be determined by the contents of each\n",
    "        column, individually.\n",
    "    comments : str, optional\n",
    "        The character used to indicate the start of a comment.\n",
    "        All the characters occurring on a line after a comment are discarded\n",
    "    delimiter : str, int, or sequence, optional\n",
    "        The string used to separate values.  By default, any consecutive\n",
    "        whitespaces act as delimiter.  An integer or sequence of integers\n",
    "        can also be provided as width(s) of each field.\n",
    "    skiprows : int, optional\n",
    "        `skiprows` was removed in numpy 1.10. Please use `skip_header` instead.\n",
    "    skip_header : int, optional\n",
    "        The number of lines to skip at the beginning of the file.\n",
    "    skip_footer : int, optional\n",
    "        The number of lines to skip at the end of the file.\n",
    "    converters : variable, optional\n",
    "        The set of functions that convert the data of a column to a value.\n",
    "        The converters can also be used to provide a default value\n",
    "        for missing data: ``converters = {3: lambda s: float(s or 0)}``.\n",
    "    missing : variable, optional\n",
    "        `missing` was removed in numpy 1.10. Please use `missing_values`\n",
    "        instead.\n",
    "    missing_values : variable, optional\n",
    "        The set of strings corresponding to missing data.\n",
    "    filling_values : variable, optional\n",
    "        The set of values to be used as default when the data are missing.\n",
    "    usecols : sequence, optional\n",
    "        Which columns to read, with 0 being the first.  For example,\n",
    "        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns.\n",
    "    names : {None, True, str, sequence}, optional\n",
    "        If `names` is True, the field names are read from the first valid line\n",
    "        after the first `skip_header` lines.\n",
    "        If `names` is a sequence or a single-string of comma-separated names,\n",
    "        the names will be used to define the field names in a structured dtype.\n",
    "        If `names` is None, the names of the dtype fields will be used, if any.\n",
    "    excludelist : sequence, optional\n",
    "        A list of names to exclude. This list is appended to the default list\n",
    "        ['return','file','print']. Excluded names are appended an underscore:\n",
    "        for example, `file` would become `file_`.\n",
    "    deletechars : str, optional\n",
    "        A string combining invalid characters that must be deleted from the\n",
    "        names.\n",
    "    defaultfmt : str, optional\n",
    "        A format used to define default field names, such as \"f%i\" or \"f_%02i\".\n",
    "    autostrip : bool, optional\n",
    "        Whether to automatically strip white spaces from the variables.\n",
    "    replace_space : char, optional\n",
    "        Character(s) used in replacement of white spaces in the variables\n",
    "        names. By default, use a '_'.\n",
    "    case_sensitive : {True, False, 'upper', 'lower'}, optional\n",
    "        If True, field names are case sensitive.\n",
    "        If False or 'upper', field names are converted to upper case.\n",
    "        If 'lower', field names are converted to lower case.\n",
    "    unpack : bool, optional\n",
    "        If True, the returned array is transposed, so that arguments may be\n",
    "        unpacked using ``x, y, z = loadtxt(...)``\n",
    "    usemask : bool, optional\n",
    "        If True, return a masked array.\n",
    "        If False, return a regular array.\n",
    "    loose : bool, optional\n",
    "        If True, do not raise errors for invalid values.\n",
    "    invalid_raise : bool, optional\n",
    "        If True, an exception is raised if an inconsistency is detected in the\n",
    "        number of columns.\n",
    "        If False, a warning is emitted and the offending lines are skipped.\n",
    "    max_rows : int,  optional\n",
    "        The maximum number of rows to read. Must not be used with skip_footer\n",
    "        at the same time.  If given, the value must be at least 1. Default is\n",
    "        to read the entire file.\n",
    "\n",
    "        .. versionadded:: 1.10.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        Data read from the text file. If `usemask` is True, this is a\n",
    "        masked array.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    numpy.loadtxt : equivalent function when no data is missing.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * When spaces are used as delimiters, or when no delimiter has been given\n",
    "      as input, there should not be any missing data between two fields.\n",
    "    * When the variables are named (either by a flexible dtype or with `names`,\n",
    "      there must not be any header in the file (else a ValueError\n",
    "      exception is raised).\n",
    "    * Individual values are not stripped of spaces by default.\n",
    "      When using a custom converter, make sure the function does remove spaces.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] NumPy User Guide, section `I/O with NumPy\n",
    "           <http://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html>`_.\n",
    "\n",
    "    Examples\n",
    "    ---------\n",
    "    >>> from io import StringIO\n",
    "    >>> import numpy as np\n",
    "\n",
    "    Comma delimited file with mixed dtype\n",
    "\n",
    "    >>> s = StringIO(\"1,1.3,abcde\")\n",
    "    >>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),\n",
    "    ... ('mystring','S5')], delimiter=\",\")\n",
    "    >>> data\n",
    "    array((1, 1.3, 'abcde'),\n",
    "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])\n",
    "\n",
    "    Using dtype = None\n",
    "\n",
    "    >>> s.seek(0) # needed for StringIO example only\n",
    "    >>> data = np.genfromtxt(s, dtype=None,\n",
    "    ... names = ['myint','myfloat','mystring'], delimiter=\",\")\n",
    "    >>> data\n",
    "    array((1, 1.3, 'abcde'),\n",
    "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])\n",
    "\n",
    "    Specifying dtype and names\n",
    "\n",
    "    >>> s.seek(0)\n",
    "    >>> data = np.genfromtxt(s, dtype=\"i8,f8,S5\",\n",
    "    ... names=['myint','myfloat','mystring'], delimiter=\",\")\n",
    "    >>> data\n",
    "    array((1, 1.3, 'abcde'),\n",
    "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])\n",
    "\n",
    "    An example with fixed-width columns\n",
    "\n",
    "    >>> s = StringIO(\"11.3abcde\")\n",
    "    >>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],\n",
    "    ...     delimiter=[1,3,5])\n",
    "    >>> data\n",
    "    array((1, 1.3, 'abcde'),\n",
    "          dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', '|S5')])\n",
    "\n",
    "    \"\"\"\n",
    "    if max_rows is not None:\n",
    "        if skip_footer:\n",
    "            raise ValueError(\n",
    "                    \"The keywords 'skip_footer' and 'max_rows' can not be \"\n",
    "                    \"specified at the same time.\")\n",
    "        if max_rows < 1:\n",
    "            raise ValueError(\"'max_rows' must be at least 1.\")\n",
    "\n",
    "    # Py3 data conversions to bytes, for convenience\n",
    "    if comments is not None:\n",
    "        comments = asbytes(comments)\n",
    "    if isinstance(delimiter, unicode):\n",
    "        delimiter = asbytes(delimiter)\n",
    "    if isinstance(missing_values, (unicode, list, tuple)):\n",
    "        missing_values = asbytes_nested(missing_values)\n",
    "\n",
    "    #\n",
    "    if usemask:\n",
    "        from numpy.ma import MaskedArray, make_mask_descr\n",
    "    # Check the input dictionary of converters\n",
    "    user_converters = converters or {}\n",
    "    if not isinstance(user_converters, dict):\n",
    "        raise TypeError(\n",
    "            \"The input argument 'converter' should be a valid dictionary \"\n",
    "            \"(got '%s' instead)\" % type(user_converters))\n",
    "\n",
    "    # Initialize the filehandle, the LineSplitter and the NameValidator\n",
    "    own_fhd = False\n",
    "    try:\n",
    "        if is_pathlib_path(fname):\n",
    "            fname = str(fname)\n",
    "        if isinstance(fname, basestring):\n",
    "            if sys.version_info[0] == 2:\n",
    "                fhd = iter(np.lib._datasource.open(fname, 'rbU'))\n",
    "            else:\n",
    "                fhd = iter(np.lib._datasource.open(fname, 'rb'))\n",
    "            own_fhd = True\n",
    "        else:\n",
    "            fhd = iter(fname)\n",
    "    except TypeError:\n",
    "        raise TypeError(\n",
    "            \"fname must be a string, filehandle, list of strings, \"\n",
    "            \"or generator. Got %s instead.\" % type(fname))\n",
    "\n",
    "    split_line = LineSplitter(delimiter=delimiter, comments=comments,\n",
    "                              autostrip=autostrip)._handyman\n",
    "    validate_names = NameValidator(excludelist=excludelist,\n",
    "                                   deletechars=deletechars,\n",
    "                                   case_sensitive=case_sensitive,\n",
    "                                   replace_space=replace_space)\n",
    "\n",
    "    # Skip the first `skip_header` rows\n",
    "    for i in range(skip_header):\n",
    "        next(fhd)\n",
    "\n",
    "    # Keep on until we find the first valid values\n",
    "    first_values = None\n",
    "    try:\n",
    "        while not first_values:\n",
    "            first_line = next(fhd)\n",
    "            if names is True:\n",
    "                if comments in first_line:\n",
    "                    first_line = (\n",
    "                        b''.join(first_line.split(comments)[1:]))\n",
    "            first_values = split_line(first_line)\n",
    "    except StopIteration:\n",
    "        # return an empty array if the datafile is empty\n",
    "        first_line = b''\n",
    "        first_values = []\n",
    "        warnings.warn('genfromtxt: Empty input file: \"%s\"' % fname, stacklevel=2)\n",
    "\n",
    "    # Should we take the first values as names ?\n",
    "    if names is True:\n",
    "        fval = first_values[0].strip()\n",
    "        if fval in comments:\n",
    "            del first_values[0]\n",
    "\n",
    "    # Check the columns to use: make sure `usecols` is a list\n",
    "    if usecols is not None:\n",
    "        try:\n",
    "            usecols = [_.strip() for _ in usecols.split(\",\")]\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                usecols = list(usecols)\n",
    "            except TypeError:\n",
    "                usecols = [usecols, ]\n",
    "    nbcols = len(usecols or first_values)\n",
    "\n",
    "    # Check the names and overwrite the dtype.names if needed\n",
    "    if names is True:\n",
    "        names = validate_names([_bytes_to_name(_.strip())\n",
    "                                for _ in first_values])\n",
    "        first_line = b''\n",
    "    elif _is_string_like(names):\n",
    "        names = validate_names([_.strip() for _ in names.split(',')])\n",
    "    elif names:\n",
    "        names = validate_names(names)\n",
    "    # Get the dtype\n",
    "    if dtype is not None:\n",
    "        dtype = easy_dtype(dtype, defaultfmt=defaultfmt, names=names,\n",
    "                           excludelist=excludelist,\n",
    "                           deletechars=deletechars,\n",
    "                           case_sensitive=case_sensitive,\n",
    "                           replace_space=replace_space)\n",
    "    # Make sure the names is a list (for 2.5)\n",
    "    if names is not None:\n",
    "        names = list(names)\n",
    "\n",
    "    if usecols:\n",
    "        for (i, current) in enumerate(usecols):\n",
    "            # if usecols is a list of names, convert to a list of indices\n",
    "            if _is_string_like(current):\n",
    "                usecols[i] = names.index(current)\n",
    "            elif current < 0:\n",
    "                usecols[i] = current + len(first_values)\n",
    "        # If the dtype is not None, make sure we update it\n",
    "        if (dtype is not None) and (len(dtype) > nbcols):\n",
    "            descr = dtype.descr\n",
    "            dtype = np.dtype([descr[_] for _ in usecols])\n",
    "            names = list(dtype.names)\n",
    "        # If `names` is not None, update the names\n",
    "        elif (names is not None) and (len(names) > nbcols):\n",
    "            names = [names[_] for _ in usecols]\n",
    "    elif (names is not None) and (dtype is not None):\n",
    "        names = list(dtype.names)\n",
    "\n",
    "    # Process the missing values ...............................\n",
    "    # Rename missing_values for convenience\n",
    "    user_missing_values = missing_values or ()\n",
    "\n",
    "    # Define the list of missing_values (one column: one list)\n",
    "    missing_values = [list([b'']) for _ in range(nbcols)]\n",
    "\n",
    "    # We have a dictionary: process it field by field\n",
    "    if isinstance(user_missing_values, dict):\n",
    "        # Loop on the items\n",
    "        for (key, val) in user_missing_values.items():\n",
    "            # Is the key a string ?\n",
    "            if _is_string_like(key):\n",
    "                try:\n",
    "                    # Transform it into an integer\n",
    "                    key = names.index(key)\n",
    "                except ValueError:\n",
    "                    # We couldn't find it: the name must have been dropped\n",
    "                    continue\n",
    "            # Redefine the key as needed if it's a column number\n",
    "            if usecols:\n",
    "                try:\n",
    "                    key = usecols.index(key)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            # Transform the value as a list of string\n",
    "            if isinstance(val, (list, tuple)):\n",
    "                val = [str(_) for _ in val]\n",
    "            else:\n",
    "                val = [str(val), ]\n",
    "            # Add the value(s) to the current list of missing\n",
    "            if key is None:\n",
    "                # None acts as default\n",
    "                for miss in missing_values:\n",
    "                    miss.extend(val)\n",
    "            else:\n",
    "                missing_values[key].extend(val)\n",
    "    # We have a sequence : each item matches a column\n",
    "    elif isinstance(user_missing_values, (list, tuple)):\n",
    "        for (value, entry) in zip(user_missing_values, missing_values):\n",
    "            value = str(value)\n",
    "            if value not in entry:\n",
    "                entry.append(value)\n",
    "    # We have a string : apply it to all entries\n",
    "    elif isinstance(user_missing_values, bytes):\n",
    "        user_value = user_missing_values.split(b\",\")\n",
    "        for entry in missing_values:\n",
    "            entry.extend(user_value)\n",
    "    # We have something else: apply it to all entries\n",
    "    else:\n",
    "        for entry in missing_values:\n",
    "            entry.extend([str(user_missing_values)])\n",
    "\n",
    "    # Process the filling_values ...............................\n",
    "    # Rename the input for convenience\n",
    "    user_filling_values = filling_values\n",
    "    if user_filling_values is None:\n",
    "        user_filling_values = []\n",
    "    # Define the default\n",
    "    filling_values = [None] * nbcols\n",
    "    # We have a dictionary : update each entry individually\n",
    "    if isinstance(user_filling_values, dict):\n",
    "        for (key, val) in user_filling_values.items():\n",
    "            if _is_string_like(key):\n",
    "                try:\n",
    "                    # Transform it into an integer\n",
    "                    key = names.index(key)\n",
    "                except ValueError:\n",
    "                    # We couldn't find it: the name must have been dropped,\n",
    "                    continue\n",
    "            # Redefine the key if it's a column number and usecols is defined\n",
    "            if usecols:\n",
    "                try:\n",
    "                    key = usecols.index(key)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            # Add the value to the list\n",
    "            filling_values[key] = val\n",
    "    # We have a sequence : update on a one-to-one basis\n",
    "    elif isinstance(user_filling_values, (list, tuple)):\n",
    "        n = len(user_filling_values)\n",
    "        if (n <= nbcols):\n",
    "            filling_values[:n] = user_filling_values\n",
    "        else:\n",
    "            filling_values = user_filling_values[:nbcols]\n",
    "    # We have something else : use it for all entries\n",
    "    else:\n",
    "        filling_values = [user_filling_values] * nbcols\n",
    "\n",
    "    # Initialize the converters ................................\n",
    "    if dtype is None:\n",
    "        # Note: we can't use a [...]*nbcols, as we would have 3 times the same\n",
    "        # ... converter, instead of 3 different converters.\n",
    "        converters = [StringConverter(None, missing_values=miss, default=fill)\n",
    "                      for (miss, fill) in zip(missing_values, filling_values)]\n",
    "    else:\n",
    "        dtype_flat = flatten_dtype(dtype, flatten_base=True)\n",
    "        # Initialize the converters\n",
    "        if len(dtype_flat) > 1:\n",
    "            # Flexible type : get a converter from each dtype\n",
    "            zipit = zip(dtype_flat, missing_values, filling_values)\n",
    "            converters = [StringConverter(dt, locked=True,\n",
    "                                          missing_values=miss, default=fill)\n",
    "                          for (dt, miss, fill) in zipit]\n",
    "        else:\n",
    "            # Set to a default converter (but w/ different missing values)\n",
    "            zipit = zip(missing_values, filling_values)\n",
    "            converters = [StringConverter(dtype, locked=True,\n",
    "                                          missing_values=miss, default=fill)\n",
    "                          for (miss, fill) in zipit]\n",
    "    # Update the converters to use the user-defined ones\n",
    "    uc_update = []\n",
    "    for (j, conv) in user_converters.items():\n",
    "        # If the converter is specified by column names, use the index instead\n",
    "        if _is_string_like(j):\n",
    "            try:\n",
    "                j = names.index(j)\n",
    "                i = j\n",
    "            except ValueError:\n",
    "                continue\n",
    "        elif usecols:\n",
    "            try:\n",
    "                i = usecols.index(j)\n",
    "            except ValueError:\n",
    "                # Unused converter specified\n",
    "                continue\n",
    "        else:\n",
    "            i = j\n",
    "        # Find the value to test - first_line is not filtered by usecols:\n",
    "        if len(first_line):\n",
    "            testing_value = first_values[j]\n",
    "        else:\n",
    "            testing_value = None\n",
    "        converters[i].update(conv, locked=True,\n",
    "                             testing_value=testing_value,\n",
    "                             default=filling_values[i],\n",
    "                             missing_values=missing_values[i],)\n",
    "        uc_update.append((i, conv))\n",
    "    # Make sure we have the corrected keys in user_converters...\n",
    "    user_converters.update(uc_update)\n",
    "\n",
    "    # Fixme: possible error as following variable never used.\n",
    "    #miss_chars = [_.missing_values for _ in converters]\n",
    "\n",
    "    # Initialize the output lists ...\n",
    "    # ... rows\n",
    "    rows = []\n",
    "    append_to_rows = rows.append\n",
    "    # ... masks\n",
    "    if usemask:\n",
    "        masks = []\n",
    "        append_to_masks = masks.append\n",
    "    # ... invalid\n",
    "    invalid = []\n",
    "    append_to_invalid = invalid.append\n",
    "\n",
    "    # Parse each line\n",
    "    for (i, line) in enumerate(itertools.chain([first_line, ], fhd)):\n",
    "        values = split_line(line)\n",
    "        nbvalues = len(values)\n",
    "        # Skip an empty line\n",
    "        if nbvalues == 0:\n",
    "            continue\n",
    "        if usecols:\n",
    "            # Select only the columns we need\n",
    "            try:\n",
    "                values = [values[_] for _ in usecols]\n",
    "            except IndexError:\n",
    "                append_to_invalid((i + skip_header + 1, nbvalues))\n",
    "                continue\n",
    "        elif nbvalues != nbcols:\n",
    "            append_to_invalid((i + skip_header + 1, nbvalues))\n",
    "            continue\n",
    "        # Store the values\n",
    "        append_to_rows(tuple(values))\n",
    "        if usemask:\n",
    "            append_to_masks(tuple([v.strip() in m\n",
    "                                   for (v, m) in zip(values,\n",
    "                                                     missing_values)]))\n",
    "        if len(rows) == max_rows:\n",
    "            break\n",
    "\n",
    "    if own_fhd:\n",
    "        fhd.close()\n",
    "\n",
    "    # Upgrade the converters (if needed)\n",
    "    if dtype is None:\n",
    "        for (i, converter) in enumerate(converters):\n",
    "            current_column = [itemgetter(i)(_m) for _m in rows]\n",
    "            try:\n",
    "                converter.iterupgrade(current_column)\n",
    "            except ConverterLockError:\n",
    "                errmsg = \"Converter #%i is locked and cannot be upgraded: \" % i\n",
    "                current_column = map(itemgetter(i), rows)\n",
    "                for (j, value) in enumerate(current_column):\n",
    "                    try:\n",
    "                        converter.upgrade(value)\n",
    "                    except (ConverterError, ValueError):\n",
    "                        errmsg += \"(occurred line #%i for value '%s')\"\n",
    "                        errmsg %= (j + 1 + skip_header, value)\n",
    "                        raise ConverterError(errmsg)\n",
    "\n",
    "    # Check that we don't have invalid values\n",
    "    nbinvalid = len(invalid)\n",
    "    if nbinvalid > 0:\n",
    "        nbrows = len(rows) + nbinvalid - skip_footer\n",
    "        # Construct the error message\n",
    "        template = \"    Line #%%i (got %%i columns instead of %i)\" % nbcols\n",
    "        if skip_footer > 0:\n",
    "            nbinvalid_skipped = len([_ for _ in invalid\n",
    "                                     if _[0] > nbrows + skip_header])\n",
    "            invalid = invalid[:nbinvalid - nbinvalid_skipped]\n",
    "            skip_footer -= nbinvalid_skipped\n",
    "#\n",
    "#            nbrows -= skip_footer\n",
    "#            errmsg = [template % (i, nb)\n",
    "#                      for (i, nb) in invalid if i < nbrows]\n",
    "#        else:\n",
    "        errmsg = [template % (i, nb)\n",
    "                  for (i, nb) in invalid]\n",
    "        if len(errmsg):\n",
    "            errmsg.insert(0, \"Some errors were detected !\")\n",
    "            errmsg = \"\\n\".join(errmsg)\n",
    "            # Raise an exception ?\n",
    "            if invalid_raise:\n",
    "                raise ValueError(errmsg)\n",
    "            # Issue a warning ?\n",
    "            else:\n",
    "                warnings.warn(errmsg, ConversionWarning, stacklevel=2)\n",
    "\n",
    "    # Strip the last skip_footer data\n",
    "    if skip_footer > 0:\n",
    "        rows = rows[:-skip_footer]\n",
    "        if usemask:\n",
    "            masks = masks[:-skip_footer]\n",
    "\n",
    "    # Convert each value according to the converter:\n",
    "    # We want to modify the list in place to avoid creating a new one...\n",
    "    if loose:\n",
    "        rows = list(\n",
    "            zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n",
    "                  for (i, conv) in enumerate(converters)]))\n",
    "    else:\n",
    "        rows = list(\n",
    "            zip(*[[conv._strict_call(_r) for _r in map(itemgetter(i), rows)]\n",
    "                  for (i, conv) in enumerate(converters)]))\n",
    "\n",
    "    # Reset the dtype\n",
    "    data = rows\n",
    "    if dtype is None:\n",
    "        # Get the dtypes from the types of the converters\n",
    "        column_types = [conv.type for conv in converters]\n",
    "        # Find the columns with strings...\n",
    "        strcolidx = [i for (i, v) in enumerate(column_types)\n",
    "                     if v in (type('S'), np.string_)]\n",
    "        # ... and take the largest number of chars.\n",
    "        for i in strcolidx:\n",
    "            column_types[i] = \"|S%i\" % max(len(row[i]) for row in data)\n",
    "        #\n",
    "        if names is None:\n",
    "            # If the dtype is uniform, don't define names, else use ''\n",
    "            base = set([c.type for c in converters if c._checked])\n",
    "            if len(base) == 1:\n",
    "                (ddtype, mdtype) = (list(base)[0], np.bool)\n",
    "            else:\n",
    "                ddtype = [(defaultfmt % i, dt)\n",
    "                          for (i, dt) in enumerate(column_types)]\n",
    "                if usemask:\n",
    "                    mdtype = [(defaultfmt % i, np.bool)\n",
    "                              for (i, dt) in enumerate(column_types)]\n",
    "        else:\n",
    "            ddtype = list(zip(names, column_types))\n",
    "            mdtype = list(zip(names, [np.bool] * len(column_types)))\n",
    "        output = np.array(data, dtype=ddtype)\n",
    "        if usemask:\n",
    "            outputmask = np.array(masks, dtype=mdtype)\n",
    "    else:\n",
    "        # Overwrite the initial dtype names if needed\n",
    "        if names and dtype.names:\n",
    "            dtype.names = names\n",
    "        # Case 1. We have a structured type\n",
    "        if len(dtype_flat) > 1:\n",
    "            # Nested dtype, eg [('a', int), ('b', [('b0', int), ('b1', 'f4')])]\n",
    "            # First, create the array using a flattened dtype:\n",
    "            # [('a', int), ('b1', int), ('b2', float)]\n",
    "            # Then, view the array using the specified dtype.\n",
    "            if 'O' in (_.char for _ in dtype_flat):\n",
    "                if has_nested_fields(dtype):\n",
    "                    raise NotImplementedError(\n",
    "                        \"Nested fields involving objects are not supported...\")\n",
    "                else:\n",
    "                    output = np.array(data, dtype=dtype)\n",
    "            else:\n",
    "                rows = np.array(data, dtype=[('', _) for _ in dtype_flat])\n",
    "                output = rows.view(dtype)\n",
    "            # Now, process the rowmasks the same way\n",
    "            if usemask:\n",
    "                rowmasks = np.array(\n",
    "                    masks, dtype=np.dtype([('', np.bool) for t in dtype_flat]))\n",
    "                # Construct the new dtype\n",
    "                mdtype = make_mask_descr(dtype)\n",
    "                outputmask = rowmasks.view(mdtype)\n",
    "        # Case #2. We have a basic dtype\n",
    "        else:\n",
    "            # We used some user-defined converters\n",
    "            if user_converters:\n",
    "                ishomogeneous = True\n",
    "                descr = []\n",
    "                for i, ttype in enumerate([conv.type for conv in converters]):\n",
    "                    # Keep the dtype of the current converter\n",
    "                    if i in user_converters:\n",
    "                        ishomogeneous &= (ttype == dtype.type)\n",
    "                        if ttype == np.string_:\n",
    "                            ttype = \"|S%i\" % max(len(row[i]) for row in data)\n",
    "                        descr.append(('', ttype))\n",
    "                    else:\n",
    "                        descr.append(('', dtype))\n",
    "                # So we changed the dtype ?\n",
    "                if not ishomogeneous:\n",
    "                    # We have more than one field\n",
    "                    if len(descr) > 1:\n",
    "                        dtype = np.dtype(descr)\n",
    "                    # We have only one field: drop the name if not needed.\n",
    "                    else:\n",
    "                        dtype = np.dtype(ttype)\n",
    "            #\n",
    "            output = np.array(data, dtype)\n",
    "            if usemask:\n",
    "                if dtype.names:\n",
    "                    mdtype = [(_, np.bool) for _ in dtype.names]\n",
    "                else:\n",
    "                    mdtype = np.bool\n",
    "                outputmask = np.array(masks, dtype=mdtype)\n",
    "    # Try to take care of the missing data we missed\n",
    "    names = output.dtype.names\n",
    "    if usemask and names:\n",
    "        for (name, conv) in zip(names or (), converters):\n",
    "            missing_values = [conv(_) for _ in conv.missing_values\n",
    "                              if _ != b'']\n",
    "            for mval in missing_values:\n",
    "                outputmask[name] |= (output[name] == mval)\n",
    "    # Construct the final array\n",
    "    if usemask:\n",
    "        output = output.view(MaskedArray)\n",
    "        output._mask = outputmask\n",
    "    # Verify that the array has at least dimensions `ndmin`.\n",
    "    # Check correctness of the values of `ndmin`\n",
    "    if ndmin not in [0, 1, 2]:\n",
    "        raise ValueError('Illegal value of ndmin keyword: %s' % ndmin)\n",
    "    # Tweak the size and shape of the arrays - remove extraneous dimensions\n",
    "    if output.ndim > ndmin:\n",
    "        output = np.squeeze(output)\n",
    "    # and ensure we have the minimum number of dimensions asked for\n",
    "    # - has to be in this order for the odd case ndmin=1, X.squeeze().ndim=0\n",
    "    if output.ndim < ndmin:\n",
    "        if ndmin == 1:\n",
    "            output = np.atleast_1d(output)\n",
    "        elif ndmin == 2:\n",
    "            output = np.atleast_2d(output).T\n",
    "    if unpack:\n",
    "        return output.T\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'genfromtxt_v1.py'; 'genfromtxt_v1' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-9aee4b774937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgenfromtxt_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'genfromtxt_v1.py'; 'genfromtxt_v1' is not a package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import genfromtxt_v1 as gft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[0], [1], [2]]])\n",
    "y = np.array([[1, 2, 3]])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fullname = pathname + filename\n",
    "data1 = np.genfromtxt(\"one_row1.csv\", delimiter=',')\n",
    "data2 = np.genfromtxt(\"one_col1.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asbytes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-e5206cb07679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_row1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_col1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-1711a3e89d89>\u001b[0m in \u001b[0;36mgft\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, ndmin, usemask, loose, invalid_raise, max_rows)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# Py3 data conversions to bytes, for convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcomments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asbytes' is not defined"
     ]
    }
   ],
   "source": [
    "new1 = gft(\"one_row1.csv\")\n",
    "new2 = gft(\"one_col1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bug = np.genfromtxt(\"scalar.csv\", delimiter=',')\n",
    "bug1 = np.loadtxt(\"scalar.csv\", delimiter=',', ndmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datal1 = np.loadtxt(\"one_row1.csv\", delimiter=',', unpack=False, ndmin=2)\n",
    "datal2 = np.loadtxt(\"one_col1.csv\", delimiter=',', unpack=False, ndmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.atleast_2d(data1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.arange(9).reshape((1,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape = (1, -1)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row1, row2, row3 = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row1, row2, row3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
